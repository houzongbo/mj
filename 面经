1. dll加载方式
动态链接库
  动态 静态
  链接时期不同：编译期和运行期
  静态链接：编译期就将dll链接到文件，体积大。
  动态链接：在运行期，才进行链接。
2. 线程池 内存池
  并发   内存碎片
3. epoll, poll, select
  IO多路复用，通过一个描述符，来监控多个io调用，当有io调用事件出触发，就可以让线程来处理。 优点在于节省线程。
  select有监视描述符数量限制，select和poll都是在事件触发时无法返回具体确认的io描述符，但是epoll会，无需轮训。
  内核和内存copy交互，epoll只有一次，将就绪的描述符维护在内核的就绪队列上。
  
5. stl

6. tcp udp 

8. lt et
    LT:当描述符就绪时，线程可以先不处理，但是下次调用epoll——wait时再通知，适合阻塞和非阻塞。 触发次数多。
    ET：必须马上处理，否则下次不通知，适用非阻塞。
    
    就绪列表中删不删除触发的io事件。
9. c c++  struct 区别
   c:不能有函数，变量体的集合。
   
10. tcp 序列号，确认号
  传输中：保证时序性，每次传输接收方成功都会发送确认数据包，确认号就是接收的序列号加上数据包长度。，如果三次错误就会重传。
  连接时：三次握手 保证链接成功。完成序号的初始化。
  
11. get post
  get 是请求资源，尔post是传输实体。
  get的参数都在url中，而post参数在实体中。而且get有长度限制。1024kb， get也只能传ASCII字符。
  get只是读取资源，回退无法对服务器造成改动，而post可以通过实体改变服务器。
  get 可缓存，post不可。
  
  get通常是用来请求资源，而post用来提交表单。但post也可以获取资源。
  get相比来说安全性低，参数包在url之中，post参数藏在body实体之中。
  get可以被浏览器缓存，而post一般不缓存。
  get请求发送产生一个tcp数据包，将header和body一起发送出去。 post一般分成两部，第一次只发送header，服务器响应100后再发送body。
  
  post一般分成两个数据包，一次发header，第二次发data。 get会发header+data。
14. 微服务
    单体应用：功能开发打包一起。就像传统客户端与服务器交互，可以负载均衡支持多服务器，cdn加载静态资源。但只是部署进行了优化。
    代码臃肿，容错性差，开发协作困难。
    
    微服务：面向服务的架构思想。
    1.单一职责的，一个微服务应该都是单一职责的。
    2. 面向服务的。将自己的业务能力封装并对外提供服务。
    
    服务发现：服务注册中心
    服务配置管理的问题：配置中心
    


17. redis
  单线程内存型键值数据库，string,set,list,hash,zset. 支持持久化。 
  与memcache：1持久化，2内存大小 3支持类型
  内部结构：dic， 跳跃表（多指针链表，能二分查找）
  过期删除，内存淘汰。
  
18. vector, hashmap,lru,shared_ptr,快排，堆排, 快速中位数

int partition(vector<int>& s,int l,int r){
  int p=s[r],i=l,j=r;
  while(i<j){
    while(s[i]<p) ++i;
    s[j]=s[i];
    while(s[j]>p) --j;
    s[i]=s[j];
  }
  s[i]=p;
return i;
}

void quicksort(vector<int>& s,int l,int r){
  if(l>=r) return ;
  int p=partition(s,l,r);
  quicksort(s,l,p-1);
  quicksort(s,p+1,r);
}

void maxheap(vector<int>& s, int i, int size){
  int l=i*2+1,r=i*2+2,large=i;
  if(s[l]>s[large]) large=l;
  if(s[r]>s[large]) large=r;
  if(large!=i) maxheap(s,large,size)
}

void buildheap(vector<int>& s,int size){
  for (int i=size/2;i>=0;--i{
    maxheap(s,i,size);
  }

}

19.strcpy,strncpy, memcpy,memmove

  strncpy: 超出count的部分用‘\0’补。
  memmove：对于dst在src后面且有重叠时，要从后往前复制。

20. 高并发tcp
  第一，tcp连接数量不局限于端口数，而是linux系统最大可打开文件数。ulimit-n 可以查看最大文件数。
                第一步，修改/etc/security/limits.conf文件，在文件中添加如下行：
                speng soft nofile 10240
                speng hard nofile 10240
                第二步，修改/etc/pam.d/login文件，在文件中添加如下行：
                session required /lib/security/pam_limits.so
                第三步，查看Linux系统级的最大打开文件数限制，使用如下命令：
                [speng@as4 ~]$ cat /proc/sys/fs/file-max
                12158
  第二，使用支持高并发网络I/O的编程技术，非阻塞io，io多路复用。
  
  12. 多线程

  13. 设计模式
  
  单例模式：
    确保一个类只有一个实例，并提供该实例的全局访问点。 构造函数private
    饿汉模式
    懒汉模式：性能高，但有线程安全问题。 二检锁，静态类对象。
    
  观察者模式：
    定义对象之间的一对多依赖，当一个对象状态改变时，它的所有依赖都会收到通知并且自动更新状态。
    主题（Subject）具有注册和移除观察者、并通知所有观察者的功能，主题是通过维护一张观察者列表来实现这些操作的。
    观察者（Observer）的注册功能需要调用主题的 registerObserver() 方法。
  
  简单工厂：
    将实例化操作单独放一个类中，工厂类。将产品类型作为参数，工厂类来操作具体实例化哪个产品实例。
  工厂方法：
    将工厂类也抽象化，不同的产品通过不同的工厂来创建实例。
  抽象工厂模式：
    工厂方法就已经完成了对工厂类的抽象，但是工厂方法只适用于产品种类单一的情况，一个工厂为一类产品提供借口；但是抽象工厂可以通过一个工厂生产多个产品，有多个产品实例化的接口。
    
  生产者-消费者模式：
    经典的多线程并发协作模式。将生产和消费解藕，通过两种线程以共享内存（内核缓冲区）的方式进行数据交流。
    通常需要条件变量和mutex来保证线程的同步机制。
    
    
    
    
    
 14. 常用协议，端口号。
      http:   80   tcp
      https:  443  tcp
      dns:    53   udp
      ftp:    21(控制连接） 20 （数据连接） tcp
      telnet：23    tcp
      
 15. 如何让udp可靠
 
    三种可靠等级：尽力可靠，无序可靠，有序可靠。
    tcp缺点：速度慢，网络环境要求高，延迟问题；3次握手，4次挥手 占用资源； 重传占用带宽
    
    核心：
        重传模式：超时重传，请求重传，FEC选择重传。
                
                1 超时重传：依赖于ack回复，等待rto时间。  
                2 请求重传：接收端发送是ack时附带上丢失的报文信息。 序号
                3. FEC选择重传：前向纠错技术，在发送端将报文进行FEC分组，在接收端丢包能根据FEC分组算法还原。
                
      rto=srtt+srtt_var
      
        窗口与拥塞控制：避免带宽占用过高
        
 16. 大量time_wait 怎么解决  （端口占用）
 
 服务器关闭连接后，客户端还会在发送确认后等待time_wait时间，造成大量time_wait占用端口，socket。后面的客户端可能连接不上。（端口号占用）65535
 尤其在高并发短连接问题大。 
 
      1 Time_wait 客户端   连接复用       sysctl.conf      tcp_tw_reuse=1
      客户端再次向同一个服务器发起连接时，复用之前 tw的连接。    （短连接不断重连）
      
      2. Time_wait连接回收   tcp_tw_recycle=1
      内核快速回收socket，（rto） 将socket销毁。  加快timewait  容易造成数据混乱。
      
      
      3. tcp_timestamps=1  
      保存两个时间，1个是发送数据包的时间，1个是最近接收数据包的时间。 reuse 和recycle依赖于timestemp
      
      
      
 17 socket:
   五元组：源ip，源端口，目的ip，目的端口，类型。
    
    
    
  18. static 在类外初始化；
      const 在构造函数中初始化
      static const 可以直接类内初始化
    
19. 拷贝构造函数：&   左值引用
    移动构造函数：&&  右值引用  通常和move搭配


21。 RTTI 运行时类型识别： typeid， dynamic_cast
                      带虚函数在运行期识别，不带在编译期识别。
  
  
  22. decltype   auto
  
  
  23. c++ 11 新特性 ： 智能指针，移动语意，stl容器，auto关键字，lambda表达式
  
  24. linux实现系统调用：
      软中断。  产生一个异常，导致cpu会切换到内核态去处理异常，而异常处理函数就是系统调用函数。
  
  25. shared_ptr 线程安全问题
  
      当多线程读写shared_ptr 指向的同一个对象时，可能会发生竞态。 需要加互斥锁来保护。
      
      std::mutex m;
      unique_lock<mutex> lock(m);
  
  
  26. c++源文件到可执行文件
      预处理阶段：预处理器指令实现文本的替换
      编译阶段：将c++语言翻译汇编语言，汇编文件
      汇编阶段：成机器语言，目标文件
      链接阶段：引用别处的函数，数据。例如标准库和私有库。将目标文件代码和引用的代码连接起来。 可执行文件
      
      
  27. 负载均衡工具：
      LVS：四层负载均衡linux virtual server
      Nginx：七层负载均衡 网页服务器， 
      HAProxy：七层负载均衡


28. 数据库索引
    mysql： B+树
          聚簇索引：在B+树叶子结点中存储全部行数据（有序）， 按照主键建索引。
          二级索引：如果先给其他字段加索引，要 create index。。。on table（字段）；
                  此时数据库建立一个新B+树， 叶子结点只存字段对应主键。
                  查找的时候对照两个表找数据。 回表
          复合索引：create index 。。。 on table （字段1，字段2）；
                    此时数据库又建立一个新B+树，叶子结点存复合字段对应主键。
          
    索引最左匹配原则：
          联合索引中，只能用于查找key组合是否存在，遇到范围查询，后面的索引无法命中。从左到右命中索引。
          
          
          尽量找区分度高的做索引
          
 29. stl中 map，set采用红黑树结构存储数据，相比二叉搜索树，红黑树能保证平衡，查找复杂度平均O（logn）。
      跟节点，叶子结点都是黑色。红色节点子节点必须是黑色的。 通过旋转来做到平衡限制。  最长距离不超过最短的二倍。 路径黑色节点数量相等。
      
      

30. http无状态协议：浏览器对事务处理没有记忆能力，不会记住用户的操作。
    记忆话用户状态信息用到cookie。
    
31. http header： 通用标头，实体标头，请求标头（请求方法，host，版本号），响应标头（状态码，版本号）。
    
32. tcpdump 网络抓包，分析工具。 将数据包头部截取。


33. tcp 三次握手异常 分析
     第一次握手SYN丢包：  隔时间收不到SYN ACK，超时重传，重传次数linux内核指定，等待时间2的指数幂增长。 tcp_syn_retries
     第二次SYN ACK丢包：此时客户端等待SYNACK，而服务器在等待ACK。理论上都会造成超时重传。 但是服务器超时重传只会触发一次，就会再收到SYN包，造成重置。tcp_synack_retries
                      最后也会因为SYN的超时重传终止。
     第三次ACK丢包： 此时服务器等不到ACK 超时重传SYNACK, tcp_synack_retries  。 但客户端处于established状态。 传输数据也会造成重传。tcp_retries。
                  客户端断开established状态：tcp保活机制。tcp_keetalive_time。
              
34. 发送窗口和 MSS：
    窗口：一次发送最多字节数。
    MSS：一个数据包最多字节数。分包           窗口/MSS 一次最多数据包数量
 
35. tcp数据包累计确认机制：
     当收到多个数据包时，不需要为所有包确认，只需要确认最后一个包。
     
     
36. tcp避免小数据报文传输：
    tcp包含20字节头部，数据字节少会造成效率低。
    nagle算法：有发送未确认字节，会囤积起来直到MSS。
    
37. tcp fast open 避免三次握手
    首次连接需要三次握手，但fast open会以cookie形式存在客户端。
    以后的连接，客户端可以直接传数据，附带cookie。
    
38. time_wait作用：1.保证连接正确关闭，防止ack没有到达服务器（被动方）。
                  2. 确保连接中没有旧数据包残存，不会关闭后留在网络中。
                  时间为2MSL
                  
39. pcb 进程控制块
    1 进程描述信息（pid）， 2 进程管理信息（状态，优先级）， 3 资源分配清单，  4 cpu状态信息，上下文（cpu寄存器-程序计数器）
    
    pcb存在系统内核之中。是进程的唯一标示。

40. 进程创建：
    1 分配进程标识号pid， 2. 申请空pcb 3. 分配资源   4. 初始化pcb 
    
41。 pcb组织方式：
    通常通过链表，  就绪队列， 阻塞队列。。。
    
42. cpu上下文切换：（寄存器）
    将当前进程上下文存起来（内核，pcb），找到下一个进程并加载其上下文，跳转到程序计数器所指位置。
    
43. 进程上下文切换：（内核态）
    除了 堆栈，代码段，data，bss 等用户态内存资源。  还要切换内核堆栈，寄存器等资源。
    
    首先要通过分页机制找到下一个进程用户态资源的内存位置，可能造成缺页中断。
    然后还要从下一个进程pcb中提取cpu上下文，进行cpu上下文切换。
    
44.线程内容：
    独立的栈空间和线程控制块（寄存器）。   可以共享进程的资源。
    
    线程缺点：一个线程挂掉可能影响进程中其他线程。
    
45. 进程 线程区别

    。进称是资源分配的单位，线程是独立调度的单位。 线程需共享使用进程的用户态内存资源。
    。进程创建，切换，销毁的开销更大。 进程创建需要通过虚拟内存机制独立分配一块内存资源。进程切换需要考虑切换虚拟内存页，可能造成缺页中断。
      同一进程下的线程切换只会切换栈和寄存器等私有资源。
    。线程通信通常只在用户态进行内存的共享，不需要内核参与。 而进程通信需要陷入内核。
    
46. 线程实现
    用户线程1，内核线程，轻量级线程。
    用户线程：线程控制块在用户态中，不对内核可见。只由用户级线程库函数来处理。
            无需系统调用，速度快。   线程可以通过函数共享进程的cpu时间片，执行会慢。 切换不受内核影响，设计困难。
            
    内核线程：线程控制块在内核中， 通过cpu时间片轮转来获取执行时间。
            当一个线程系统调用而阻塞时，不影响其他线程。
            
    轻量级线程：内核支持的用户级线程。   与内核线程一对一。
    
    
47. 最大tcp连接数：
    理论上是客户端ip数*客户端端口数    2^32 * 2^16
    但通常受限于机能，最大打开文件数。 因为tcp连接也是一个socket文件。
    
48. tcp三次握手：
    避免服务器打开多余的历史连接，造成初始化混乱。
    完成序列号初始化并确认。
    
49. 分片工作在网络层，  mss有什么用

    在网络层：效率更高，不需要考虑上层协议。
    
    mtu：链路层最大传输单元 一般1500
    mss：传输层tcp最大报文段大小 一般1460=1500-20-20； 
    
    当一个ip分片丢失，整个ip报文都要重传。 但网络层IP没有重传机制，需要传输层tcp负责重传。所以ip层分片也很没效率。
    所以为了更高效率，避免ip分片，就可以在tcp连接时协商mss值，在传输层就分好片，到ip层就不用分层了。
    
    
50. tcp 洪泛攻击（dos）
    攻击者通过不同ip地址对服务器频繁进行syn连接，但是不返回第三次握手ack。
    这样服务器端在listen socket监听到连接，将他放入等待连接完成的队列。大量无效syn进入会占据队列空间，导致服务器无法处理新连接。
    
    
    syn cookie防治： 当syn队列满了后，收到syn包不进入队列 而是计算cookie值，将cookie值以syn ack 方式传递回客户端，
                    若收到ack直接进入accept队列。
                    
              
51。 建立连接后，客户端故障？
    tcp保活机制。 每隔时间发送探测报文，若没有响应，则认为死亡。
    
52. ipv4 地址： 
       1 ip分类：
          32位   网络号+主机号
          主机号全0:指定网络
          主机全号1: 网络中所有主机
          
          第一位0:A类地址   
          第二位0: B类地址
          第三位0: C类地址
          
        2 无分类地址：
            最后/x:  前x位为网络号。
            
        3 子网掩码：（掩盖掉主机号区域）
            ip地址32 + 子网掩码32
            两者按位and结果就是网络号。
            
53. 分离网络号和主机号：
    网络号代表同一广播域（同一链路），路由器寻址先按网络号发到网络上。
    

54. 子网划分：
    将主机地址划分为子网主机地址和子网网络地址。
    子网掩码的主机号区1表示子网网络地址  0表示子网主机地址
    
 55. 公有ip 私有ip：
      公有ip由组织分配，在互联网保持唯一。
      
      
 56. ipv6 地址128位     与ipv4不兼容
        ipv6取消 分片，  取消首部检验   ，首部40字节。
        
 57. dns解析：
    1.客户端发出dns请求，先查自身本地dns缓存。
    2. 再查本地dns服务器；
    3. 本地dns服务器再查根域名服务器，根域名服务器告诉顶级域名服务器地址
    
    4.本地dns服务器再查顶级域名服务器，告诉权威dns服务器地址
    5. 权威dns服务器会告诉ip
    6. 本地dns服务器最后将ip返回
    
    
 58. 传输ip数据包 到链路层中需要下一跳mac地址    ARP
    
    主机存ARP高速缓存。  没命中就会广播ARP请求，满足ip就返回mac地址。
    
    
 59. NAT： 网络地址转换
      ipv4地址紧缺，同一个公司，学校，机构可以用私有ip地址，与外部通信时通过NAT表转换为公有ip。
      
      不同 IP 相同 端口号 -> 相同ip  不同端口号
    
 60. icmp：
      网络层中 辅助ip的一个协议，确保ip数据包交付成功，报告失败的原因。
      
      询问报文：ping
      差错报文：traceroute

 61. 进程通信：
    1. 管道：半双工通信，先进先出，只能在血缘进程间通信。 管道就是内核中的一块缓存
            int pipe(int fd[2]);    fd[0]:读取端描述符   fd[1]：写入端描述符
            可以发现 进程描述符存于一个进程中。   因此只能在父子进程之间才能通过管道通信。 使用fork来复制描述符
            管道 半双工  只能一端输入，另一段输出。
            
    2. 命名管道： 取消对关系的限制。
                pipe是通过描述符创建的描述符来作为输出和写入的端口。
                而mkfifo创建了类型为管道的文件。  进程通过该管道通信。
                
    3. 消息队列：加入中间件，解耦读写。
              管道效率低，不适合频繁通信。必须一端写，另一端读。管道不能独立于读写存在 半双工。生命跟随进程
              
              消息队列是内核中的消息链表，先进先出。 可以独立于读写，写操作直接写入队列，读操作直接从队列里拿。生命跟随内核。
              不适合大数据的传输 有长度限制，通信实时性也不高。
              
    4. 共享内存：速度快
              进程各自拿出一块虚拟内存，共同映射到相同的物理内存上。
              
    5. 信号量：
            共享内存会造成数据竞争，信号量可以帮助构建同步机制。 让进程按顺序进入临界区。
            p操作：共享资源之前，信号量-1，小于0会阻塞等待。
            v：共享资源之后，信号量+1，小于等于0会唤醒阻塞进程，大于0说明没有阻塞。
            
       互斥锁： 只有两个互斥值的信号量，能构成互斥      
            
    6. 信号：
            工作异常需要信号通知进程。  唯一的异步通信机制。
            
            sigint：终止进程   sigtstp：停止进程，不结束。 sigkill 立即结束进程
            
    7. socket：
              可以在不同主机间通信
    
    
62. https:
          http+ ssl(secure socket layer)    ssl独立于应用层
          防治明文监听，伪装，篡改。
          
          非对称密钥
          证书 签名机制                CA数字证书：附带公钥；  服务器自带私钥；   服务器响应请求再将数字证书发给客户端。客户端签名验证后将随机key发给服务器
                                                                          服务器再用随机key加密返回客户端。

63. I/O ：
      物理io：从实际存储设备中获取数据 
      逻辑io：从逻辑存储器中获取数据（块，缓冲区）
      
      
      
64. 双层缓冲区：
              应用进程缓冲区：  避免阻塞（读的时候没有数据，写得时候满了）； 读的时候容避免不完整或者读多。
              
              内核缓冲区：缓冲区会占据内存。直接打到进程缓冲区会占据大量内存无法换页。 所以引入内核缓冲区，内核缓冲区满了再换入进程缓冲区
              
    双缓冲：在内核构建两个缓冲区，避免一个缓冲区满了，无法接受新的写入。
    循环缓冲：一个缓冲区，俩指针，一个指向空闲字，一个指向第一个未删除的字，两者到达顶点时，返回底部。
    
65. io：
        应用进程， 内核， 数据
        
        一阶段：内核准备数据，打入内核缓冲区中。
        二阶段：将内核缓冲区数据打入进程缓冲区中。
        
        阻塞/非阻塞：区分在一阶段，调用者等待方式不同，阻塞：休眠，直到通知准备好。不占用cpu资源。
                                               非阻塞：轮训，占用cpu资源。
                                               
        同步/异步：区分在二阶段：调用完成的方式不同。 同步：数据准备好后，由调用者进行数据拷贝工作。
                                               异步：数据准备好后，直接由内核拷贝到用户态，并用回调函数告诉调用者请求完成。
         

66. 多线程：
          线程写共享内存（互斥区）：1.寄存器从内存中读取数据
                       2. 寄存器更新数据
                       3. 寄存器将数据写入内存中
                       
           线程安全问题 （竟态问题）： 在执行步骤三前有另一个线程开始步骤一。
           
           
67. 同步和互斥：
     
     互斥：保证多线程不能同时进入临界区。
     同步：多线程之间有执行顺序依赖
     
     锁：解决互斥问题。
        
        忙等锁（自旋锁）：若锁被占用，调用者不会睡眠，而是一直循环等待锁的释放。 占用cpu
        互斥锁： 锁被占用，调用者陷入睡眠 
        
        自旋锁可用条件变量替代，取消忙等。  信号量
        
        
68。 哲学家进餐问题：
              
              信号量+互斥锁   ：  互斥进入临界区； 信号量模拟拿左叉，拿右叉，放左叉，放右叉。
     
              think();
              P(mutex);
              P(fork[i]);
              P(fork[(i+1)%n]);
              eat();
              V(fork[i]);
              Vfork[(i+1)%n]);
              V(mutex);

69. linux内存 段页式存储：
      分段：将程序内存按物理内存顺序存储，但是容易有内存碎片（外部碎片）。
      分页：将程序分称逻辑页，每个页通过页表对应物理位置。但是容易产生数据覆盖问题。
      
      段页式：弥补两者缺点，  在按顺序分称段的前提下，在段中分成多个页。
      
      linux：程序段，初始化数据段data，未初始化数据段bss，堆，栈。

70. TLB：
      页表缓存，省去了到内存读页表的步骤。


71. 乐观锁，悲观锁
    
    乐观锁：总是认为数据不会改变，不用必须加锁，只有当数据真改变了，再进行回滚操作。
    CAS：乐观锁的实现方式之一，轻量级锁。
         读取数据时不加锁，准备写入数据时查询比较原值，如果修改了，则重新读数据。  （比较+更新是原子操作）
         问题：CAS操作一直回滚的话，会造成自旋状态，占用cpu资源； aba问题，可能造成反复读写，但结果没变，线程查不出来。 a->b->a（加时间戳）
         
    悲观锁，总是认为数据会发生竞争，所以每次读写前都要加锁。
    synchronized 互斥锁
    

72. c++ 多态：
          多态就是指多种状态，通常分为静态多态和动态多态。
          静态多态发生在编译期，通过函数重载实现，相同的函数名，不同的函数形参。
          c++多态一般说的都是动态多态，发生在运行期，通常通过虚函数来实现，基类指针指向派生类对象，调用函数时会按照动态类型（派生类）来调用实际函数。
          
    虚函数：由虚函数表来实现。
          整个动态多态就是一个三级指针结构。
          
          首先，要有一个基类指针指向派生类对象。发生虚函数覆盖。
          其次，派生类对象在构造的时候会创建一个虚函数指针指向派生类的虚函数表。
          最后，每个多态继承系统下的类都会维护一个虚函数表，虚函数表中存放的都是函数指针，也就是实际函数的地址。
    
73. c++新特性
        移动语意，move，右值引用； lambda； auto； 智能指针shared_ptr ；stl容器
         

74. c++内存泄漏：
        解决：使用对象来管理资源（RAII），c++11中引入了shared_ptr 引用计数。
        内存泄漏排查：linux： valgrind


